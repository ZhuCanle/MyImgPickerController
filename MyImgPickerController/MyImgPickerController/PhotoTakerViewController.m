//
//  PhotoTakerViewController.m
//  MyImgPickerController
//
//  Created by lwj on 15/6/25.
//  Copyright (c) 2015å¹´ root. All rights reserved.
//

#import "PhotoTakerViewController.h"

#import "UIView+ZCLQuickControl.h"

#import <Masonry.h>
#import <SVProgressHUD.h>

#define MAX_RECORD_TIME 15
#define PROGRESS_MOVE_PERTIME 0.0006667

@interface PhotoTakerViewController () <UIAlertViewDelegate,AVCaptureFileOutputRecordingDelegate>
{
    AVCaptureSession *_captureSession;//ä¼šè¯ï¼Œè´Ÿè´£è¾“å…¥å’Œè¾“å‡ºè®¾å¤‡ä¹‹é—´çš„æ•°æ®ä¼ é€’
    AVCaptureDeviceInput *_videoCaptureDeviceInput;//è´Ÿè´£ä»AVCaptureDeviceè·å¾—è¾“å…¥æ•°æ®
    AVCaptureDeviceInput *_audioCaptureDeviceInput;
    AVCaptureMovieFileOutput *_captureMovieFileOutput;//éŸ³é¢‘è¾“å‡ºæµ
    AVCaptureVideoPreviewLayer *_captureVideoPreviewLayer;//ç›¸æœºæ‹æ‘„é¢„è§ˆå›¾å±‚
    AVAssetWriter *_writer;
    AVAssetWriterInput *_writerInput;
    
    UIButton *_recordBtn;
    UIProgressView *_filmProgress;
    NSTimer *_progressTimer;
    UILabel *_releaseLabel;
    UIAlertView *_finishAlert;
    UIView *_darkView;
    NSString *_outputFielPath;// åŸè§†é¢‘æ–‡ä»¶è¾“å‡ºè·¯å¾„
    NSString *_outputFilePathLow;// å‹ç¼©åè§†é¢‘æ–‡ä»¶è¾“å‡ºè·¯å¾„
    BOOL _isProcessingData;
    BOOL _isCancel;// å–æ¶ˆå½•åˆ¶æ ‡è®°ï¼ˆå–æ¶ˆå½•åˆ¶æ“ä½œåä¸è¿›è¡Œè§†é¢‘è£å‰ªå’Œå‹ç¼©å¤„ç†ï¼‰
}

@end

@implementation PhotoTakerViewController

// ä¼šè¯ã€è®¾å¤‡ã€è¾“å…¥å¯¹è±¡ã€è¾“å‡ºå¯¹è±¡ã€é¢„è§ˆå±‚

#pragma mark - VCç”Ÿå‘½å‘¨æœŸ
- (void)viewDidLoad {
    [super viewDidLoad];
    // Do any additional setup after loading the view.
    _outputFielPath = [NSTemporaryDirectory() stringByAppendingString:@"myMovie.mov"];
    _outputFilePathLow = [NSTemporaryDirectory() stringByAppendingString:@"myMovieLow.mov"];
    
    _isCancel = NO;
    
    [self createUI];
    
    [self configCaptureSessionAndPreview];
}

- (void)viewWillAppear:(BOOL)animated
{
    [_captureSession startRunning];
}

- (void)viewWillDisappear:(BOOL)animated
{
    [_captureSession stopRunning];
}

- (void)didReceiveMemoryWarning {
    [super didReceiveMemoryWarning];
    // Dispose of any resources that can be recreated.
}

- (BOOL)shouldAutorotate
{
    return self.enableRotation;
}

#pragma mark - åˆ›å»ºè§†å›¾
- (void)createUI
{
    self.view.backgroundColor = [UIColor blackColor];
    
    // å–æ™¯æ¡†
    _viewContainer = [[UIView alloc] initWithFrame:CGRectMake(0, 20, self.view.frame.size.width, self.view.frame.size.width*1)];
    //_viewContainer.backgroundColor = [UIColor redColor];
    _viewContainer.backgroundColor = [UIColor clearColor];
    [self.view addSubview:_viewContainer];
    
    // å½•åˆ¶æŒ‰é’®
    _recordBtn = [UIButton buttonWithType:UIButtonTypeCustom];
    [_recordBtn setBackgroundImage:[UIImage imageNamed:@"08341911.png"] forState:UIControlStateNormal];
    [self.view addSubview:_recordBtn];
    //_record = [self.view addCustomButtonAtNormalStateWithFrame:CGRectMake(0, 0, 0, 0) imageName:@"green-button-for-web.jpg" title:nil titleColor:nil fontSize:15 fontName:nil aligmentType:NSTextAlignmentCenter];
    [_recordBtn mas_makeConstraints:^(MASConstraintMaker *make) {
        make.bottom.mas_equalTo(@-110);
        make.centerX.mas_equalTo(self.view.mas_centerX);
        make.size.mas_equalTo(CGSizeMake(100, 100));
    }];
    [_recordBtn setBackgroundImage:[UIImage imageNamed:@"0834192.png"] forState:UIControlStateHighlighted];
    [_recordBtn addTarget:self action:@selector(holdRecord:) forControlEvents:UIControlEventTouchDown];
    [_recordBtn addTarget:self action:@selector(releaseRecord:) forControlEvents:UIControlEventTouchUpInside];
    [_recordBtn addTarget:self action:@selector(cancelRecord:) forControlEvents:UIControlEventTouchUpOutside];
    
    // å½•åˆ¶è¿›åº¦
    _filmProgress = [[UIProgressView alloc] initWithProgressViewStyle:UIProgressViewStyleDefault];
    [self.view addSubview:_filmProgress];
    [_filmProgress mas_makeConstraints:^(MASConstraintMaker *make) {
        make.top.with.equalTo(_viewContainer.mas_bottom).with.offset(0);
        make.width.mas_equalTo(self.view.mas_width);
        make.height.mas_equalTo(@3);
        make.centerX.mas_equalTo(self.view.mas_centerX);
    }];
    _filmProgress.progressTintColor = [UIColor redColor];
    _filmProgress.progress = 0;
    
    // å¯¹ç„¦æ¡†
    self.focusCursor = [[UIImageView alloc] initWithImage:[UIImage imageNamed:@"f096.png"]];
    self.focusCursor.frame = CGRectMake(0, 0, 60, 60);
    self.focusCursor.alpha = 0;
    [_viewContainer addSubview:self.focusCursor];

    // å–æ¶ˆæç¤º
    _releaseLabel = [self.view addLabelWithFrame:CGRectMake(0, 0, 0, 0) text:@"ğŸ‘†ä¸Šæ‹‰å–æ¶ˆğŸ‘†" textColor:[UIColor redColor] fontSize:16 fontName:nil aligmentType:NSTextAlignmentCenter];
    _releaseLabel.alpha = 0;
    [_releaseLabel mas_makeConstraints:^(MASConstraintMaker *make) {
        make.top.mas_equalTo(_filmProgress.mas_bottom).with.offset(10);
        make.size.mas_equalTo(CGSizeMake(180, 23));
        make.centerX.mas_equalTo(self.view.mas_centerX);
    }];
}

#pragma mark - æ‹æ‘„åŠŸèƒ½
- (void)configCaptureSessionAndPreview
{
    // åˆå§‹åŒ–ä¼šè¯
    _captureSession = [[AVCaptureSession alloc] init];
    if([_captureSession canSetSessionPreset:AVCaptureSessionPreset352x288])
    {
        _captureSession.sessionPreset = AVCaptureSessionPreset640x480;
    }
    // è·å¾—è¾“å…¥è®¾å¤‡
    // è§†é¢‘è¾“å…¥è®¾å¤‡
    AVCaptureDevice *videoCaptureDevice = [self getCameraDeviceWithPosition:AVCaptureDevicePositionBack];//è·å–åç½®æ‘„åƒå¤´
    if(!videoCaptureDevice)
    {
        NSLog(@"æ— æ³•è·å–åç½®æ‘„åƒå¤´");
    }
//    [videoCaptureDevice lockForConfiguration:nil];
//    AVCaptureDeviceFormat *format = [[videoCaptureDevice formats] firstObject];
////    for(AVCaptureDeviceFormat *format in [videoCaptureDevice formats])
////    {
////        NSLog(@"%@",format.formatDescription);
////    }
//    videoCaptureDevice.activeFormat = videoCaptureDevice.formats[4];
//    NSLog(@"%@",videoCaptureDevice.activeFormat.formatDescription);
//    CMTime max = ((AVFrameRateRange *)[videoCaptureDevice.activeFormat.videoSupportedFrameRateRanges firstObject]).maxFrameDuration;
//    CMTime min = ((AVFrameRateRange *)[videoCaptureDevice.activeFormat.videoSupportedFrameRateRanges firstObject]).minFrameDuration;
//    NSLog(@"%u,%d,%lld",max.flags,max.timescale,max.value);
    
//    [videoCaptureDevice setActiveVideoMaxFrameDuration:min];
//    [videoCaptureDevice setActiveVideoMinFrameDuration:min];
//    [videoCaptureDevice unlockForConfiguration];
    // éŸ³é¢‘è¾“å…¥è®¾å¤‡
    AVCaptureDevice *audioCaptureDevice = [[AVCaptureDevice devicesWithMediaType:AVMediaTypeAudio] firstObject];
    
    // åˆå§‹åŒ–è®¾å¤‡è¾“å…¥å¯¹è±¡ï¼Œç”¨äºè·å–è¾“å…¥æ•°æ®
    NSError *error = nil;
    _videoCaptureDeviceInput = [[AVCaptureDeviceInput alloc] initWithDevice:videoCaptureDevice error:&error];
    if(error)
    {
        NSLog(@"è·å–è¾“å…¥å¯¹è±¡ï¼Œ%@",error.localizedDescription);
        return;
    }
    _audioCaptureDeviceInput = [[AVCaptureDeviceInput alloc] initWithDevice:audioCaptureDevice error:&error];
    if(error)
    {
        NSLog(@"è·å–è¾“å…¥å¯¹è±¡ï¼Œ%@",error.localizedDescription);
        return;
    }
    
    // åˆå§‹åŒ–è®¾å¤‡è¾“å‡ºå¯¹è±¡ï¼Œè·å–è¾“å‡ºæ•°æ®
    _captureMovieFileOutput = [[AVCaptureMovieFileOutput alloc] init];
    
    // å°†è¾“å…¥å¯¹è±¡åŠ å…¥ä¼šè¯
    if([_captureSession canAddInput:_videoCaptureDeviceInput]&&[_captureSession canAddInput:_audioCaptureDeviceInput])
    {
        [_captureSession addInput:_videoCaptureDeviceInput];
        [_captureSession addInput:_audioCaptureDeviceInput];
//        NSDictionary *dic = [[NSDictionary alloc] initWithObjects:@[[NSNumber numberWithUnsignedInt:kCVPixelFormatType_32BGRA],[NSNumber numberWithInt:240],[NSNumber numberWithInt:320]] forKeys:@[(NSString *)kCVPixelBufferPixelFormatTypeKey,(NSString *)kCVPixelBufferWidthKey,(NSString *)kCVPixelBufferHeightKey]];
//        _captureMovieFileOutput.videoSettings = dic;
        AVCaptureConnection *captureConnection = [_captureMovieFileOutput connectionWithMediaType:AVMediaTypeVideo];
        captureConnection.videoOrientation = AVCaptureVideoOrientationLandscapeRight;
        [captureConnection setVideoOrientation:AVCaptureVideoOrientationLandscapeLeft];
        NSLog(@"%d",captureConnection.isVideoOrientationSupported);
        if([captureConnection isVideoStabilizationSupported])
        {
            captureConnection.preferredVideoStabilizationMode = AVCaptureVideoStabilizationModeAuto;
        }
    }
    
    // å°†è¾“å‡ºè®¾å¤‡åŠ å…¥ä¼šè¯
    if([_captureSession canAddOutput:_captureMovieFileOutput])
    {
        [_captureSession addOutput:_captureMovieFileOutput];
    }
    
    // åˆ›å»ºè§†é¢‘é¢„è§ˆå±‚ï¼Œå®æ—¶å±•ç¤ºæ‘„åƒå¤´çŠ¶æ€
    _captureVideoPreviewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:_captureSession];
    CALayer *layer = _viewContainer.layer;
    layer.masksToBounds = YES;
    _captureVideoPreviewLayer.frame = layer.bounds;
    _captureVideoPreviewLayer.videoGravity = AVLayerVideoGravityResizeAspectFill;//å¡«å……æ¨¡å¼
    
    // é¢„è§ˆå±‚æ·»åŠ åˆ°ç•Œé¢ä¸­
    [layer insertSublayer:_captureVideoPreviewLayer below:self.focusCursor.layer];
    
    // è®¾ç½®æ˜¯å¦å¯æ—‹è½¬ï¼ˆå¤–éƒ¨è°ƒç”¨è®¾ç½®çš„è¯æ³¨é‡Šæ‰ï¼‰ï¼Œæ·»åŠ å¯¹ç„¦æ‰‹åŠ¿ï¼›
    _enableRotation = NO;
    [self addGenstureRecognizer];
}

-(void)addGenstureRecognizer{
    UITapGestureRecognizer *tapGesture=[[UITapGestureRecognizer alloc]initWithTarget:self action:@selector(tapScreen:)];
    [self.viewContainer addGestureRecognizer:tapGesture];
}

-(void)setFocusCursorWithPoint:(CGPoint)point{
    self.focusCursor.center=point;
    self.focusCursor.transform=CGAffineTransformMakeScale(1.5, 1.5);
    self.focusCursor.alpha=1.0;
    [UIView animateWithDuration:1.0 animations:^{
        self.focusCursor.transform=CGAffineTransformIdentity;
    } completion:^(BOOL finished) {
        self.focusCursor.alpha=0;
        
    }];
}

-(void)focusWithMode:(AVCaptureFocusMode)focusMode exposureMode:(AVCaptureExposureMode)exposureMode atPoint:(CGPoint)point{
    [self changeDeviceProperty:^(AVCaptureDevice *captureDevice) {
        // åˆ¤æ–­å½“å‰çš„å¯¹ç„¦æ¨¡å¼ã€å¯¹ç„¦æ¨¡å¼æ˜¯å¦æ”¯æŒï¼Œå¹¶æ ¹æ®æ‰‹åŠ¿è®¾ç½®æ–°çš„å¯¹ç„¦åŠæ›å…‰å‚æ•°ã€‚
        if ([captureDevice isFocusModeSupported:focusMode]) {
            [captureDevice setFocusMode:AVCaptureFocusModeAutoFocus];
        }
        if ([captureDevice isFocusPointOfInterestSupported]) {
            [captureDevice setFocusPointOfInterest:point];
        }
        if ([captureDevice isExposureModeSupported:exposureMode]) {
            [captureDevice setExposureMode:AVCaptureExposureModeAutoExpose];
        }
        if ([captureDevice isExposurePointOfInterestSupported]) {
            [captureDevice setExposurePointOfInterest:point];
        }
    }];
}

// å½•åˆ¶æŒ‰é’®ä¸­è°ƒç”¨æ­¤æ–¹æ³•æ¥å¼€å§‹ã€ç»“æŸå½•åˆ¶ï¼›
- (void)takeButtonClick
{
    // æ ¹æ®è®¾å¤‡è¾“å‡ºè·å¾—è¿æ¥
    AVCaptureConnection *captureConnection=[_captureMovieFileOutput connectionWithMediaType:AVMediaTypeVideo];
    // æ ¹æ®è¿æ¥å–å¾—è®¾å¤‡è¾“å‡ºçš„æ•°æ®
    if (![_captureMovieFileOutput isRecording]) {
        self.enableRotation=NO;
        // å¦‚æœæ”¯æŒå¤šä»»åŠ¡åˆ™å¼€å§‹å¤šä»»åŠ¡
        if ([[UIDevice currentDevice] isMultitaskingSupported]) {
            self.backgroundTaskIdentifier=[[UIApplication sharedApplication] beginBackgroundTaskWithExpirationHandler:nil];
        }
        // é¢„è§ˆå›¾å±‚å’Œè§†é¢‘æ–¹å‘ä¿æŒä¸€è‡´
        captureConnection.videoOrientation=[_captureVideoPreviewLayer connection].videoOrientation;
        // è§†é¢‘ä¿å­˜åˆ°æ²™ç›’ä¸­
        NSString *outputFielPath=[NSTemporaryDirectory() stringByAppendingString:@"myMovie.mov"];
        NSURL *fileUrl=[NSURL fileURLWithPath:outputFielPath];
        [_captureMovieFileOutput startRecordingToOutputFileURL:fileUrl recordingDelegate:self];
    }
    else{
        [_captureMovieFileOutput stopRecording];//åœæ­¢å½•åˆ¶
    }
//    NSError *error = nil;
//    _writer = [[AVAssetWriter alloc] initWithURL:[NSURL fileURLWithPath:_outputFielPath] fileType:AVFileTypeQuickTimeMovie error:&error];
//    NSParameterAssert(_writer);
//    if(error)
//    {
//        NSLog(@"%@",[error localizedDescription]);
//    }
//    CGSize size = CGSizeMake(352, 288);
//    NSDictionary *videoCompressionProps = [NSDictionary dictionaryWithObjectsAndKeys:[NSNumber numberWithDouble:128.0*1024.0],AVVideoAverageBitRateKey,nil];
//    NSDictionary *videoSettings = [NSDictionary dictionaryWithObjectsAndKeys:AVVideoCodecH264, AVVideoCodecKey,[NSNumber numberWithInt:size.width], AVVideoWidthKey,[NSNumber numberWithInt:size.height],AVVideoHeightKey,videoCompressionProps, AVVideoCompressionPropertiesKey, nil];
//    _writerInput = [AVAssetWriterInput assetWriterInputWithMediaType:AVMediaTypeVideo outputSettings:videoSettings];
//    NSParameterAssert(_writerInput);
//    _writerInput.expectsMediaDataInRealTime = YES;
//    NSDictionary *sourcePixelBufferAttributesDictionary = [NSDictionary dictionaryWithObjectsAndKeys:[NSNumber numberWithInt:kCVPixelFormatType_32ARGB],kCVPixelBufferPixelFormatTypeKey, nil];
}

/**
 *  æ”¹å˜è®¾å¤‡å±æ€§çš„ç»Ÿä¸€æ“ä½œæ–¹æ³•
 *
 *  @param propertyChange å±æ€§æ”¹å˜æ“ä½œ
 */
-(void)changeDeviceProperty:(void (^)(AVCaptureDevice *captureDevice))propertyChange
{
    AVCaptureDevice *captureDevice= [_videoCaptureDeviceInput device];
    NSError *error;
    //æ³¨æ„æ”¹å˜è®¾å¤‡å±æ€§å‰ä¸€å®šè¦é¦–å…ˆè°ƒç”¨lockForConfiguration:è°ƒç”¨å®Œä¹‹åä½¿ç”¨unlockForConfigurationæ–¹æ³•è§£é”
    if ([captureDevice lockForConfiguration:&error]) {
        propertyChange(captureDevice);
        [captureDevice unlockForConfiguration];
    }else{
        NSLog(@"è®¾ç½®è®¾å¤‡å±æ€§è¿‡ç¨‹å‘ç”Ÿé”™è¯¯ï¼Œé”™è¯¯ä¿¡æ¯ï¼š%@",error.localizedDescription);
    }
}

-(AVCaptureDevice *)getCameraDeviceWithPosition:(AVCaptureDevicePosition )position{
    NSArray *cameras= [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
    for (AVCaptureDevice *camera in cameras) {
        if ([camera position]==position) {
            return camera;
        }
    }
    return nil;
}

#pragma mark - è§†é¢‘åˆå¹¶ã€è£å‰ªã€å‹ç¼©
// æŠŠè§†é¢‘è£å‰ªæˆæ­£æ–¹å½¢å¹¶å‹ç¼©
- (void)mergeVideoWithFinished:(void (^)(void))finished
{
    //
    AVMutableComposition *composition = [[AVMutableComposition alloc] init];//åˆå§‹åŒ–å‰ªè¾‘å¯¹è±¡
    CMTime totalDuration = kCMTimeZero;//è§†é¢‘é•¿åº¦ï¼Œé¢„è®¾ä¸º0ï¼›
    AVAsset *asset = [AVAsset assetWithURL:[NSURL fileURLWithPath:_outputFielPath]];//ç”¨åŸè§†é¢‘åˆå§‹åŒ–ä¸€ä¸ªassetå¯¹è±¡
    AVAssetTrack *videoAssetTrack = [[asset tracksWithMediaType:AVMediaTypeVideo] firstObject];//å–å…¶è§†é¢‘è½¨
    
    AVMutableCompositionTrack *audioTrack = [composition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];//åˆå§‹åŒ–ä¸€ä¸ªéŸ³è½¨å‰ªè¾‘å¯¹è±¡
    [audioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, asset.duration) ofTrack:[[asset tracksWithMediaType:AVMediaTypeAudio] firstObject] atTime:kCMTimeZero error:nil];//æŠŠåŸè§†é¢‘assetçš„éŸ³æ’å…¥éŸ³è½¨å‰ªè¾‘å¯¹è±¡ï¼ŒèŒƒå›´æ˜¯è§†é¢‘èµ·å§‹åˆ°æœ€åä¸€ç§’ï¼Œæ’å…¥ä½ç½®ä¸º0ç§’ã€‚
    AVMutableCompositionTrack *videoTrack = [composition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];//åˆå§‹åŒ–ä¸€ä¸ªè§†é¢‘å‰ªè¾‘å¯¹è±¡
    [videoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, asset.duration) ofTrack:videoAssetTrack atTime:kCMTimeZero error:nil];//æŠŠåŸè§†é¢‘assetçš„è§†é¢‘è½¨æ’å…¥è§†é¢‘å‰ªè¾‘å¯¹è±¡ï¼ŒèŒƒå›´æ˜¯è§†é¢‘èµ·å§‹åˆ°æœ€åä¸€ç§’ï¼Œæ’å…¥ä½ç½®ä¸º0ç§’ã€‚

    AVMutableVideoCompositionLayerInstruction *layerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:videoTrack];//ç”¨è§†é¢‘å‰ªè¾‘å¯¹è±¡åˆ›å»ºä¸€ä¸ªlayerInstructionï¼Œè¯¥å¯¹è±¡ç”¨äºè£å‰ªè§†é¢‘ã€æ¨¡ç³ŠåŒ–ç­‰æ“ä½œï¼›
    totalDuration = CMTimeAdd(totalDuration, asset.duration);//è§†é¢‘æ€»é•¿
    
    // è·å–å‰ªè¾‘åŒºåŸŸ
    CGSize renderSize = CGSizeMake(0, 0);
    renderSize.width = MAX(renderSize.width, videoAssetTrack.naturalSize.height);
    renderSize.height = MAX(renderSize.height, videoAssetTrack.naturalSize.width);
    CGFloat renderW = MIN(renderSize.width, renderSize.height);
    CGFloat rate;
    rate = renderW / MIN(videoAssetTrack.naturalSize.width, videoAssetTrack.naturalSize.height);
    CGAffineTransform layerTransform = CGAffineTransformMake(videoAssetTrack.preferredTransform.a, videoAssetTrack.preferredTransform.b, videoAssetTrack.preferredTransform.c, videoAssetTrack.preferredTransform.d, videoAssetTrack.preferredTransform.tx * rate, videoAssetTrack.preferredTransform.ty * rate);
    layerTransform = CGAffineTransformConcat(layerTransform, CGAffineTransformMake(1, 0, 0, 1, 0, -(videoAssetTrack.naturalSize.width - videoAssetTrack.naturalSize.height) / 2.0));//å‘ä¸Šç§»åŠ¨å–ä¸­éƒ¨å½±å“
    layerTransform = CGAffineTransformScale(layerTransform, rate, rate);//æ”¾ç¼©ï¼Œè§£å†³å‰åæ‘„åƒç»“æœå¤§å°ä¸å¯¹ç§°
    // æŠŠè¯¥åŒºåŸŸè®¾å®šä¸ºlayerInstructionçš„å‰ªè¾‘åŒºåŸŸ
    [layerInstruction setTransform:layerTransform atTime:kCMTimeZero];
    [layerInstruction setOpacity:0.0 atTime:totalDuration];
    
    AVMutableVideoCompositionInstruction *instruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];//åˆ›å»ºä¸€ä¸ªå‰ªè¾‘æŒ‡ä»¤
    instruction.timeRange = CMTimeRangeMake(kCMTimeZero, totalDuration);//æ—¶é—´ä¸ºä»è§†é¢‘èµ·å§‹åˆ°ç»“æŸ
    instruction.layerInstructions = @[layerInstruction];//è®¾å®šå‰ªè¾‘åŒºåŸŸä¸ºä¸Šé¢çš„layerInstructionå¯¹è±¡ï¼Œæ”¾åœ¨æ•°ç»„ä¸­ã€‚
    AVMutableVideoComposition *mainComposition = [AVMutableVideoComposition videoComposition];//åˆ›å»ºä¸€ä¸ªè§†é¢‘å‰ªè¾‘å¯¹è±¡
    mainComposition.instructions = @[instruction];//è®¾å®šå‰ªè¾‘æŒ‡ä»¤ä¸ºä¸Šé¢å¸¸è§çš„å‰ªè¾‘æŒ‡ä»¤ï¼Œæ”¾åœ¨æ•°ç»„ä¸­
    mainComposition.frameDuration = CMTimeMake(1, 30);//è®¾å®šå¸§é€Ÿç‡
    mainComposition.renderSize = CGSizeMake(renderW, renderW);//è®¾å®šæ¸²æŸ“åŒºåŸŸå¤§å°ï¼Œé«˜å®½å‡ä¸ºåŸè§†é¢‘çš„å®½ã€‚
    
    // å¯¼å‡ºè§†é¢‘
    AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:composition presetName:AVAssetExportPresetMediumQuality];
    exporter.videoComposition = mainComposition;
    exporter.outputURL = [NSURL fileURLWithPath:_outputFilePathLow];
    exporter.outputFileType = AVFileTypeQuickTimeMovie;
    exporter.shouldOptimizeForNetworkUse = YES;
    [exporter exportAsynchronouslyWithCompletionHandler:^{
        // ä¸ºä½•åˆ‡æ¢åˆ°ä¸»çº¿ç¨‹è¿›è¡Œç»“æŸåæ“ä½œä¼šå¿«å¾ˆå¤šå‘¢ï¼Ÿæœ‰å¾…ç ”ç©¶.
        dispatch_async(dispatch_get_main_queue(), ^{
            finished();
        });
    }];
    
}
// åˆå¹¶å’Œè£å‰ªè§†é¢‘(åŒ…å«ä¸Šä¸€ä¸ªæ–¹æ³•çš„åŠŸèƒ½)
- (void)mergeAndExportVideosAtFileURLs:(NSArray *)fileURLArray
{
    NSError *error = nil;
    
    CGSize renderSize = CGSizeMake(0, 0);
    
    NSMutableArray *layerInstructionArray = [[NSMutableArray alloc] init];
    
    AVMutableComposition *mixComposition = [[AVMutableComposition alloc] init];
    
    CMTime totalDuration = kCMTimeZero;
    
    //å…ˆå»assetTrack ä¹Ÿä¸ºäº†å–renderSize
    NSMutableArray *assetTrackArray = [[NSMutableArray alloc] init];
    NSMutableArray *assetArray = [[NSMutableArray alloc] init];
    for (NSURL *fileURL in fileURLArray) {
        AVAsset *asset = [AVAsset assetWithURL:fileURL];
        
        if (!asset) {
            continue;
        }
        
        [assetArray addObject:asset];
        
        AVAssetTrack *assetTrack = [[asset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
        [assetTrackArray addObject:assetTrack];
        
        renderSize.width = MAX(renderSize.width, assetTrack.naturalSize.height);
        renderSize.height = MAX(renderSize.height, assetTrack.naturalSize.width);
    }
    
    CGFloat renderW = MIN(renderSize.width, renderSize.height);
    
    for (int i = 0; i < [assetArray count] && i < [assetTrackArray count]; i++) {
        
        AVAsset *asset = [assetArray objectAtIndex:i];
        AVAssetTrack *assetTrack = [assetTrackArray objectAtIndex:i];
        
        AVMutableCompositionTrack *audioTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];
        [audioTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, asset.duration)
                            ofTrack:[[asset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0]
                             atTime:totalDuration
                              error:nil];
        
        AVMutableCompositionTrack *videoTrack = [mixComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];
        
        [videoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, asset.duration)
                            ofTrack:assetTrack
                             atTime:totalDuration
                              error:&error];
        
        //fix orientationissue
        AVMutableVideoCompositionLayerInstruction *layerInstruciton = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:videoTrack];
        
        totalDuration = CMTimeAdd(totalDuration, asset.duration);
        
        CGFloat rate;
        rate = renderW / MIN(assetTrack.naturalSize.width, assetTrack.naturalSize.height);
        
        CGAffineTransform layerTransform = CGAffineTransformMake(assetTrack.preferredTransform.a, assetTrack.preferredTransform.b, assetTrack.preferredTransform.c, assetTrack.preferredTransform.d, assetTrack.preferredTransform.tx * rate, assetTrack.preferredTransform.ty * rate);
        layerTransform = CGAffineTransformConcat(layerTransform, CGAffineTransformMake(1, 0, 0, 1, 0, -(assetTrack.naturalSize.width - assetTrack.naturalSize.height) / 2.0));//å‘ä¸Šç§»åŠ¨å–ä¸­éƒ¨å½±å“
        layerTransform = CGAffineTransformScale(layerTransform, rate, rate);//æ”¾ç¼©ï¼Œè§£å†³å‰åæ‘„åƒç»“æœå¤§å°ä¸å¯¹ç§°
        
        [layerInstruciton setTransform:layerTransform atTime:kCMTimeZero];
        [layerInstruciton setOpacity:0.0 atTime:totalDuration];
        
        //data
        [layerInstructionArray addObject:layerInstruciton];
    }
    
    //export
    AVMutableVideoCompositionInstruction *mainInstruciton = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
    mainInstruciton.timeRange = CMTimeRangeMake(kCMTimeZero, totalDuration);
    mainInstruciton.layerInstructions = layerInstructionArray;
    AVMutableVideoComposition *mainCompositionInst = [AVMutableVideoComposition videoComposition];
    mainCompositionInst.instructions = @[mainInstruciton];
    mainCompositionInst.frameDuration = CMTimeMake(1, 30);
    mainCompositionInst.renderSize = CGSizeMake(renderW, renderW);
    
    AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:mixComposition presetName:AVAssetExportPresetMediumQuality];
    exporter.videoComposition = mainCompositionInst;
    exporter.outputURL = [NSURL fileURLWithPath:_outputFilePathLow];
    exporter.outputFileType = AVFileTypeMPEG4;
    exporter.shouldOptimizeForNetworkUse = YES;
    [exporter exportAsynchronouslyWithCompletionHandler:^{
    }];
}

#pragma mark - AVCaptureFileOutputRecordingDelegate
// å½•åˆ¶æ“ä½œç»“æŸåçš„æ“ä½œ
- (void)captureOutput:(AVCaptureFileOutput *)captureOutput didFinishRecordingToOutputFileAtURL:(NSURL *)outputFileURL fromConnections:(NSArray *)connections error:(NSError *)error
{
    // æ•°æ®å†™å…¥ä¸­æ ‡è®°
    _isProcessingData = NO;
    
    // å–æ¶ˆæ“ä½œé€ æˆçš„åœæ­¢å½•åˆ¶è®²ä¸è¿›è¡Œåé¢çš„æ“ä½œ
    if(_isCancel==YES)
    {
        return;
    }
    
    // æ•°æ®å¤„ç†ä¸­çš„UIç•Œé¢æ•ˆæœ
    [SVProgressHUD showWithStatus:@"å¤„ç†ä¸­"];
    _darkView = [[UIView alloc] init];
    [self.view addSubview:_darkView];
    [_darkView mas_makeConstraints:^(MASConstraintMaker *make) {
        make.top.mas_equalTo(self.view.mas_top);
        make.left.mas_equalTo(self.view.mas_left);
        make.right.mas_equalTo(self.view.mas_right);
        make.bottom.mas_equalTo(self.view.mas_bottom);
    }];
    _darkView.backgroundColor = [UIColor blackColor];
    _darkView.alpha = 0.7;
    
    // è£å‰ªåŠå‹ç¼©è§†é¢‘
    NSFileManager *fileManager = [[NSFileManager alloc] init];
    if([fileManager fileExistsAtPath:_outputFilePathLow])
    {
        [fileManager removeItemAtPath:_outputFilePathLow error:nil];
    }
    if([fileManager fileExistsAtPath:_outputFielPath])
    {
        NSLog(@"æ„¿æ–‡ä»¶å­˜åœ¨");
        [self mergeVideoWithFinished:^{
        // è·å–æ–‡ä»¶å¤§å°
            NSFileManager *fileManager = [[NSFileManager alloc] init];
            long fileSizeB = [[fileManager attributesOfItemAtPath:_outputFilePathLow error:nil] fileSize];
            double fileSizeKB = fileSizeB/1024.0;
            // UIæ“ä½œ
            _finishAlert = [[UIAlertView alloc] initWithTitle:nil message:[NSString stringWithFormat:@"è§†é¢‘å½•åˆ¶å®Œæˆï¼Œæ–‡ä»¶å¤§å°%.2fKB",fileSizeKB] delegate:self cancelButtonTitle:@"é‡æ–°å½•åˆ¶" otherButtonTitles:@"é€€å‡º",nil];
            [_finishAlert show];
            [SVProgressHUD dismiss];
        }];
    }

}

// å½•åˆ¶å¼€å§‹æ—¶çš„æ“ä½œ
- (void)captureOutput:(AVCaptureFileOutput *)captureOutput didStartRecordingToOutputFileAtURL:(NSURL *)fileURL fromConnections:(NSArray *)connections
{
    // æ•°æ®å†™å…¥æ ‡è®°
    _isProcessingData = YES;
}

#pragma mark - äº‹ä»¶å“åº”
- (void)holdRecord:(UIButton *)button
{
    _progressTimer = [NSTimer scheduledTimerWithTimeInterval:0.01 target:self selector:@selector(timerRunning) userInfo:nil repeats:YES];
    
    [UIView animateWithDuration:0.2 animations:^{
        _releaseLabel.alpha = 1;
    }];
    
    if(_filmProgress.progress<1.0)
    {
        // æ ¹æ®è®¾å¤‡è¾“å‡ºè·å¾—è¿æ¥
        AVCaptureConnection *captureConnection=[_captureMovieFileOutput connectionWithMediaType:AVMediaTypeVideo];
        // æ ¹æ®è¿æ¥å–å¾—è®¾å¤‡è¾“å‡ºçš„æ•°æ®
        self.enableRotation=NO;
        // å¦‚æœæ”¯æŒå¤šä»»åŠ¡åˆ™å¼€å§‹å¤šä»»åŠ¡
        if ([[UIDevice currentDevice] isMultitaskingSupported]) {
        self.backgroundTaskIdentifier=[[UIApplication sharedApplication] beginBackgroundTaskWithExpirationHandler:nil];
        }
        // é¢„è§ˆå›¾å±‚å’Œè§†é¢‘æ–¹å‘ä¿æŒä¸€è‡´
        captureConnection.videoOrientation=[_captureVideoPreviewLayer connection].videoOrientation;
        // è§†é¢‘ä¿å­˜åˆ°æ²™ç›’ä¸­
        NSFileManager *fileManager = [[NSFileManager alloc] init];
        if([fileManager fileExistsAtPath:_outputFielPath])
        {
            NSLog(@"exist");
            [fileManager removeItemAtPath:_outputFielPath error:nil];
        }
        NSLog(@"save path is :%@",_outputFielPath);
        NSURL *fileUrl=[NSURL fileURLWithPath:_outputFielPath];
        
        [_captureMovieFileOutput startRecordingToOutputFileURL:fileUrl recordingDelegate:self];
    }
}

- (void)releaseRecord:(UIButton *)button
{
    [UIView animateWithDuration:0.2 animations:^{
        _releaseLabel.alpha = 0;
    }];
    
    _isCancel = NO;
    [_captureMovieFileOutput stopRecording];
}

- (void)cancelRecord:(UIButton *)button
{
    [UIView animateWithDuration:0.2 animations:^{
        _releaseLabel.alpha = 0;
    }];
    _filmProgress.progress = 0;
    
    _isCancel = YES;
    [_captureMovieFileOutput stopRecording];//åœæ­¢å½•åˆ¶
    NSLog(@"ccc");
}

- (void)timerRunning
{
    if(_recordBtn.highlighted==YES && _filmProgress.progress!=1)
    {
        _filmProgress.progress += PROGRESS_MOVE_PERTIME;
    }
    else
    {
        [_progressTimer invalidate];
        _filmProgress.tintColor = [UIColor greenColor];
    }
    
    if(_filmProgress.progress==1)
    {
        [_progressTimer invalidate];
        _isCancel = NO;
        [_captureMovieFileOutput stopRecording];
        [UIView animateWithDuration:0.2 animations:^{
            _releaseLabel.alpha = 0;
        }];
    }
}

-(void)tapScreen:(UITapGestureRecognizer *)tapGesture{
    CGPoint point= [tapGesture locationInView:self.viewContainer];
    // å°†UIåæ ‡è½¬åŒ–ä¸ºæ‘„åƒå¤´åæ ‡
    CGPoint cameraPoint= [_captureVideoPreviewLayer captureDevicePointOfInterestForPoint:point];
    [self setFocusCursorWithPoint:point];
    [self focusWithMode:AVCaptureFocusModeAutoFocus exposureMode:AVCaptureExposureModeAutoExpose atPoint:cameraPoint];
}

- (void)alertView:(UIAlertView *)alertView clickedButtonAtIndex:(NSInteger)buttonIndex
{
    if(alertView==_finishAlert)
    {
        switch (buttonIndex)
        {
            case 0:
            {
                [_darkView removeFromSuperview];
                _filmProgress.progress = 0;
                break;
            }
            case 1:
            {
                [_darkView removeFromSuperview];
                [self dismissViewControllerAnimated:YES completion:nil];
                break;
            }
        }
    }
}




/*
#pragma mark - Navigation

// In a storyboard-based application, you will often want to do a little preparation before navigation
- (void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender {
    // Get the new view controller using [segue destinationViewController].
    // Pass the selected object to the new view controller.
}
*/

@end
